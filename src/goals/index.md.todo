# Goals

## The Problem

_May 1st, 2023_

People today spend a large percentage of their time interacting with software. Software controls our
phones, cars, televisions, lightswitches, appliances, ATMs, subway ticket kiosks, and thousands of other
devices. It mediates every interaction we have with each other, from video calls to finance, romance, and education. This state of affairs might be okay, except that most people don't like software very much, and distrust (rightly!) the people and companies that produce it.

Software often misbehaves. Software bugs and user interface glitches frustrate and bewilder even the most intelligent among us. And even when software is working as intended, it rarely answers only to its users. Indeed, it often manipulates, surveils, and exploits those users—to the profit of its creators.

## Examples of Misbehaving Software

## Examples of Manipulative Software

## Learned Helplessness

Software makes us suffer, but we can't escape it, so we've learned to just accept the pain it causes.

## The Solution

This book is dedicated to the computer users of the world. It is an attempt to alleviate the problems they face.

Using a computer is a fundamentally intellectual activity. Because the computer is designed to automate
repetitive tasks, the patterns of explicit commands one gives it rarely repeat exactly. Every action
one takes at a computer involves absorbing information, assimilating it into one's mental model of the system,
and choosing the next action to perform. This process is inherently and irreducibly creative, personal, and unpredictable.
It seems like it should be joyful fun. So why do computers so often confuse and frustrate us?

Computers confuse us when their internal model—their "thoughts" and "awareness" of what is going on—gets out of step
with our mental model. They frustrate us when they don't give us a straightforward way to tell them to do what
we want them to do. And then, of course, there are the times when a computer simply _does the wrong thing_—that is,
has a _bug_.

This book is about a way of writing software that addresses these problems. It's all about:

- making software less confusing by making its internal state simpler, more comprehensible, and more visible.
- making software less frustrating by building in straightforward, flexible ways of controlling it.
- making software less buggy through better design, testing, and static analysis.

## The Cause

I have so far been talking about computers as if they had minds of their own, but computers—stripped down to bare silicon—are
impressively stupid, beetle-minded creatures. The thing that gives computers any semblance of intelligence is _software_.
Software is made of nothing but pure abstract structure—imagine marshmallows and toothpicks, assembled in billions of different patterns. Its purpose is to direct vast rivers of beetle-minded machine instructions so that they do useful work. Nowadays you are likely to encounter only a few different kinds of _computers_ (speaking of the bare silicon, again); it is
software that gives these very similar machines their apparently infinite variety of surface forms.

Computers are astonishingly reliable; it is rare that we find the cause of a bug in hardware (though it does happen, and the effects can be catastrophic). Software is where almost all the problems with computers come from. Software, though, is not some impersonal, implacable force; software is just other people.

When programmers program, they are thinking through the space of all the possible interactions that a user could have with their software. They describe those interactions in a tightly woven form—code. The code is a record of their thoughts and decisions. In a way, it is like an avatar of the programmer–we might even say the ghost of the programmer. When you use software, you are peering through a window into a programmer's mind.

Actually, that isn't quite accurate, because most software today is not written by individual people working alone. Software is a product of organizations: teams, companies, and open-source foundations. These organizations have their own, collective kind of
intelligence.

In many ways, the intelligence of a large organization is superhuman—it can process much more information and build vastly larger conceptual structures than any individual could manage. But by that same token it is also inhuman, and so its products often alienate us. Software products cobbled together from the garbled, fragmentary thoughts of hundreds of minds cannot help but perplex and stymie us. They cannot help but have bugs. And they cannot help but be emotionally distant from us. When software is produced by bureaucratic, hierarchical organizations, in which people are not free to create things in accordance with the real, living feeling that is within them—that software cannot _live_. It can never make us feel truly comfortable, truly understood. It can never connect us to the joy and sorrow of being alive.

You might doubt, living in 2023, that software ever could or ever will again do such a thing.

## It's Not You, It's The System



- More and more people are choosing software development as a career
  - This might be okay, except that many of them don't like the code their employer makes them work on.
    - ...and _that_ might be okay, except that when programmers don't like the code they work on, they tend not to do a very good job of improving it. The software they produce is slow, clumsy, and riddled with bugs.
    - That, in turn, makes users dislike software.
- what we have is a self-perpetuating system whose product is suffering.

(Cite _Drive_ here? Programmers need to be motivated by autonomy, mastery, and purpose because they're doing intellectual
work. Saying "we should just pay programmers enough so they do good work even if it's unpleasant" ignores psychological reality.)

Hypothesis: _Users_ also need to be motivated by autonomy, mastery, and purpose, because the act of using software is inherently
intellectual work.

Yes, for most people, a computer is just a tool, not an avocation, and they'd like to keep it that way. But a computer, like
any tool, can be pleasant or unpleasant to use.

Some people love gardening, some love cooking, some love improving and decorating their homes, some love tinkering with their cars or bikes, and some—a few—love working with computers.

Houses, land, food, cars, and computers are all necessary parts of modern life. Loving them is optional; interacting with them is not. That is to say, many people who are _affected_ by these artifacts are not emotionally _involved_ in their creation. For some people, a house is just a box that you live in, a yard is just the land the house sits on, food is just nutrition, a car is just a way to get from A to B, and a computer is just a portal to most other necessary evils. It takes time and energy to be emotionally involved in an activity—even something you do every day—so most people just choose one or two hobbies.

There is an emotional cost, though, to _having_ to interact with something that you do not love; that is, to being _affected_ without being _involved_. It tends to be alienating, intimidating, and frustrating. This is _especially_ true of interactions with computers. Things don't work and you don't know why. Then, sometimes, they _do_ work, and you still don't know why. You feel like the computer is gaslighting you. You beg or hire other people to make the problem go away, and sometimes, it goes away.

The more we try to push the computer away, to hide its terrifying blossoming complexity, the worse it gets. Every layer of indirection and abstraction brings with it the possibility of new failure modes. And yet to do the opposite—to hold the computer close, and try to understand it—is intolerable. It is intolerable, because the superficial face of the computer is vapid, commercialized, patronizing, pretentious, banal, and manipulative. It has all the aesthetic grace and gravitas of a highway billboard.

There is a positive feedback loop here, from complexity to superficiality and commercialization and back again. When individual computer users don't understand computers, corporations and governments have more power to manipulate them. The more manipulative corporations and governments get, the less attractive computers seem, and the less anyone wants to understand them.

Programmers are not immune to this feedback loop. The outline of the story is the same—just replace "corporations" with "library peddlers". I've worked in many a codebase where it seemed like the programmers hated the code and wanted to spend as little time with it as possible. "Make your change, get out quick, and hope the jenga tower doesn't fall on you" was the unspoken motto. When programmers have this attitude, the health of the code deteriorates until management notices the project is going nowhere and decides to kill it. Thus, bad software is self-destroying. We might expect it to die out, but unfortunately there's a bad project born every minute.

If this destructive positive feedback loop is the norm today, my hope is that its opposite—a constructive positive feedback loop—can be the norm of tomorrow.

---

I want people to feel connected to the world around them, and to be able to shape their lives and surroundings in a way that
suits them. I want people to realize that they have "eyes and hands"—the ability to understand what's going on, and to grasp and manipulate the materials of which their world is made. As a software practitioner, I'm _specifically_ concerned with doing this in the digital realm. Moreover, I believe that the first step has to be, not to get end users more emotionally involved with computers, but to get *people working in the software trade* more emotionally involved. If the people making the software do not love it, then it has no chance of ever being loved.

If you are a programmer, I want you to try to imagine what it would take to create software that someone could truly love. Software that inspires affection, software to which one feels akin. What could inspire someone to love a computer, or a program, in the way that one can love a beautiful cozy house, a sunny spot in the garden, or the shade of a forest?

I know what my mother would say: "I know _you_ like computers a lot, Ben, but for most people, a computer is just a tool."

Yes, and:

A house is just a box.

A garden is just land.

Food is just nutrition.

A car is just transportation.

I don't think every person has to love computers. But I want them to _be able to_. Right now, they can't. _There isn't anything lovable there_.

What would it take to create software that someone could truly love?

---

> Physician, heal thyself!

The solution starts with us: software practitioners. Programmers, designers, product managers.

## What I Think Is Needed

- technical expertise - we have to be able to execute flawlessly
- democratization - more people should be able to make their own software
- free and open source software - we need high-quality, non-commercial solutions to common problems
- better UX design
- stability: you should be able to run the same software forever without major upgrades
  - platforms must ensure backwards compatibility
    - Linux and the Web are the model here
  - open source (so you can build old software for new architectures)